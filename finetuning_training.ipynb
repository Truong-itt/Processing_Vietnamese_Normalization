{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install underthesea\n",
    "!pip install textblob\n",
    "!pip install wordcloud\n",
    "!pip install transformers safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:12.044144Z",
     "iopub.status.busy": "2024-11-25T07:32:12.043127Z",
     "iopub.status.idle": "2024-11-25T07:32:12.142674Z",
     "shell.execute_reply": "2024-11-25T07:32:12.141798Z",
     "shell.execute_reply.started": "2024-11-25T07:32:12.044106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ma_khach_hang</th>\n",
       "      <th>noi_dung_binh_luan</th>\n",
       "      <th>ngay_binh_luan</th>\n",
       "      <th>gio_binh_luan</th>\n",
       "      <th>so_sao</th>\n",
       "      <th>ma_san_pham</th>\n",
       "      <th>label_star</th>\n",
       "      <th>label_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>443</td>\n",
       "      <td>sử dụng dễ dàng rất thoải mái thư giãn tột độ</td>\n",
       "      <td>29/04/2023</td>\n",
       "      <td>17:06</td>\n",
       "      <td>5</td>\n",
       "      <td>308500015</td>\n",
       "      <td>3</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1030</td>\n",
       "      <td>sử dụng dễ dãng rất thoải mái thư giãn tột độ</td>\n",
       "      <td>30/04/2023</td>\n",
       "      <td>15:04</td>\n",
       "      <td>5</td>\n",
       "      <td>308500015</td>\n",
       "      <td>3</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>689</td>\n",
       "      <td>mình rất thích hasaki va sản phẩm tẩy trang này</td>\n",
       "      <td>30/04/2023</td>\n",
       "      <td>18:34</td>\n",
       "      <td>5</td>\n",
       "      <td>422216594</td>\n",
       "      <td>3</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2519</td>\n",
       "      <td>sản phẩm có khả năng làm sạch tốt lớp trang đi...</td>\n",
       "      <td>17/07/2022</td>\n",
       "      <td>13:48</td>\n",
       "      <td>5</td>\n",
       "      <td>204100075</td>\n",
       "      <td>3</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>402</td>\n",
       "      <td>sữa rửa mặt tốt sạch mụn mịn da đáng mua nha</td>\n",
       "      <td>15/04/2023</td>\n",
       "      <td>23:04</td>\n",
       "      <td>5</td>\n",
       "      <td>422208977</td>\n",
       "      <td>3</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ma_khach_hang                                 noi_dung_binh_luan  \\\n",
       "0   1            443      sử dụng dễ dàng rất thoải mái thư giãn tột độ   \n",
       "1   2           1030      sử dụng dễ dãng rất thoải mái thư giãn tột độ   \n",
       "2   3            689    mình rất thích hasaki va sản phẩm tẩy trang này   \n",
       "3   4           2519  sản phẩm có khả năng làm sạch tốt lớp trang đi...   \n",
       "4   5            402       sữa rửa mặt tốt sạch mụn mịn da đáng mua nha   \n",
       "\n",
       "  ngay_binh_luan gio_binh_luan  so_sao  ma_san_pham  label_star  \\\n",
       "0     29/04/2023         17:06       5    308500015           3   \n",
       "1     30/04/2023         15:04       5    308500015           3   \n",
       "2     30/04/2023         18:34       5    422216594           3   \n",
       "3     17/07/2022         13:48       5    204100075           3   \n",
       "4     15/04/2023         23:04       5    422208977           3   \n",
       "\n",
       "  label_sentiment  \n",
       "0             POS  \n",
       "1             POS  \n",
       "2             POS  \n",
       "3             POS  \n",
       "4             POS  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/comments-vn/Danh_gia_processing_final_training.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:12.485283Z",
     "iopub.status.busy": "2024-11-25T07:32:12.484369Z",
     "iopub.status.idle": "2024-11-25T07:32:12.496301Z",
     "shell.execute_reply": "2024-11-25T07:32:12.495429Z",
     "shell.execute_reply.started": "2024-11-25T07:32:12.485246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noi_dung_binh_luan</th>\n",
       "      <th>label_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sử dụng dễ dàng rất thoải mái thư giãn tột độ</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sử dụng dễ dãng rất thoải mái thư giãn tột độ</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mình rất thích hasaki va sản phẩm tẩy trang này</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sản phẩm có khả năng làm sạch tốt lớp trang đi...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sữa rửa mặt tốt sạch mụn mịn da đáng mua nha</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  noi_dung_binh_luan label_sentiment\n",
       "0      sử dụng dễ dàng rất thoải mái thư giãn tột độ             POS\n",
       "1      sử dụng dễ dãng rất thoải mái thư giãn tột độ             POS\n",
       "2    mình rất thích hasaki va sản phẩm tẩy trang này             POS\n",
       "3  sản phẩm có khả năng làm sạch tốt lớp trang đi...             POS\n",
       "4       sữa rửa mặt tốt sạch mụn mịn da đáng mua nha             POS"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['noi_dung_binh_luan', 'label_sentiment']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:12.647028Z",
     "iopub.status.busy": "2024-11-25T07:32:12.646744Z",
     "iopub.status.idle": "2024-11-25T07:32:12.656996Z",
     "shell.execute_reply": "2024-11-25T07:32:12.656165Z",
     "shell.execute_reply.started": "2024-11-25T07:32:12.647003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noi_dung_binh_luan    38\n",
       "label_sentiment        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:12.837778Z",
     "iopub.status.busy": "2024-11-25T07:32:12.837213Z",
     "iopub.status.idle": "2024-11-25T07:32:12.845817Z",
     "shell.execute_reply": "2024-11-25T07:32:12.845148Z",
     "shell.execute_reply.started": "2024-11-25T07:32:12.837748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:13.100271Z",
     "iopub.status.busy": "2024-11-25T07:32:13.099867Z",
     "iopub.status.idle": "2024-11-25T07:32:13.110481Z",
     "shell.execute_reply": "2024-11-25T07:32:13.109496Z",
     "shell.execute_reply.started": "2024-11-25T07:32:13.100240Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noi_dung_binh_luan    0\n",
       "label_sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:14.179892Z",
     "iopub.status.busy": "2024-11-25T07:32:14.179537Z",
     "iopub.status.idle": "2024-11-25T07:32:14.187295Z",
     "shell.execute_reply": "2024-11-25T07:32:14.186425Z",
     "shell.execute_reply.started": "2024-11-25T07:32:14.179861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_mapping = {'NEG': 0, 'POS': 1, 'NEU': 2}\n",
    "data['label_sentiment'] = data['label_sentiment'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:17.242186Z",
     "iopub.status.busy": "2024-11-25T07:32:17.241728Z",
     "iopub.status.idle": "2024-11-25T07:32:17.247386Z",
     "shell.execute_reply": "2024-11-25T07:32:17.246446Z",
     "shell.execute_reply.started": "2024-11-25T07:32:17.242151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Number of GPUs: 2\n",
      "GPU Name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-11-25T07:32:17.913781Z",
     "iopub.status.busy": "2024-11-25T07:32:17.913429Z",
     "iopub.status.idle": "2024-11-25T07:54:01.381014Z",
     "shell.execute_reply": "2024-11-25T07:54:01.380020Z",
     "shell.execute_reply.started": "2024-11-25T07:32:17.913751Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig đã được cập nhật với max_length = 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1548' max='1548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1548/1548 21:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.141478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.131649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.125283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig,\n",
    ")\n",
    "\n",
    "# Vô hiệu hóa cảnh báo parallelism của tokenizer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# **1. Chuẩn bị dữ liệu**\n",
    "# label_mapping = {'NEG': 0, 'POS': 1, 'NEU': 2}\n",
    "# data['label_sentiment'] = data['label_sentiment'].map(label_mapping)\n",
    "\n",
    "# Chia dữ liệu thành train và test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data[\"noi_dung_binh_luan\"], data[\"label_sentiment\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# **2. Load Tokenizer**\n",
    "model_path = \"5CD-AI/Vietnamese-Sentiment-visobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Tokenize dữ liệu\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=256)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=256)\n",
    "\n",
    "# **3. Tạo Dataset Class**\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Tạo dataset\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels.tolist())\n",
    "test_dataset = SentimentDataset(test_encodings, test_labels.tolist())\n",
    "\n",
    "# **4. Load mô hình**\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "\n",
    "if not hasattr(model, \"generation_config\") or model.generation_config is None:\n",
    "    model.generation_config = GenerationConfig.from_model_config(model.config)\n",
    "\n",
    "\n",
    "# Xóa `max_length` khỏi `model.config` nếu nó tồn tại\n",
    "if hasattr(model.config, \"max_length\"):\n",
    "    del model.config.max_length\n",
    "\n",
    "# Đảm bảo `max_length` được gán trong `generation_config`\n",
    "model.generation_config.max_length = 256\n",
    "print(\"GenerationConfig đã được cập nhật với max_length =\", model.generation_config.max_length)\n",
    "\n",
    "# **5. Thiết lập TrainingArguments**\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/results\",      # Thư mục lưu kết quả\n",
    "    eval_strategy=\"epoch\",              # Đánh giá sau mỗi epoch\n",
    "    save_strategy=\"epoch\",                    # Lưu mô hình sau mỗi epoch\n",
    "    learning_rate=2e-5,                       # Learning rate\n",
    "    per_device_train_batch_size=16,           # Batch size trên mỗi GPU\n",
    "    per_device_eval_batch_size=16,            # Batch size validation\n",
    "    num_train_epochs=3,                       # Số epoch\n",
    "    weight_decay=0.01,                        # Weight decay\n",
    "    logging_dir=\"/kaggle/working/logs\",       # Thư mục log\n",
    "    load_best_model_at_end=True,              # Load model tốt nhất sau khi train\n",
    "    fp16=True,                                # Mixed Precision\n",
    "    report_to=\"none\",                         # Tắt báo cáo tới W&B\n",
    "    dataloader_num_workers=4,                 # Số luồng xử lý dữ liệu\n",
    "    save_total_limit=2,                       # Giới hạn số lượng checkpoints\n",
    "    disable_tqdm=False,                       # Hiển thị tiến trình\n",
    ")\n",
    "\n",
    "# **6. Tạo Trainer**\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# **Khắc phục vấn đề multiprocessing**\n",
    "if __name__ == \"__main__\":\n",
    "    # **7. Huấn luyện**\n",
    "    trainer.train()\n",
    "\n",
    "    # **8. Lưu mô hình**\n",
    "    trainer.save_model(\"/kaggle/working/fine_tuned_visobert\")\n",
    "    tokenizer.save_pretrained(\"/kaggle/working/fine_tuned_visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-11-25T07:57:30.737822Z",
     "iopub.status.busy": "2024-11-25T07:57:30.737461Z",
     "iopub.status.idle": "2024-11-25T07:59:24.171365Z",
     "shell.execute_reply": "2024-11-25T07:59:24.170458Z",
     "shell.execute_reply.started": "2024-11-25T07:57:30.737794Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/results/ (stored 0%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/ (stored 0%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/sentencepiece.bpe.model (deflated 50%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/tokenizer.json (deflated 78%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/config.json (deflated 50%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/tokenizer_config.json (deflated 76%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/scheduler.pt (deflated 55%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/optimizer.pt (deflated 17%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/trainer_state.json (deflated 61%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/special_tokens_map.json (deflated 85%)\n",
      "  adding: kaggle/working/results/checkpoint-1032/rng_state.pth (deflated 25%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/ (stored 0%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/sentencepiece.bpe.model (deflated 50%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/tokenizer.json (deflated 78%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/config.json (deflated 50%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/tokenizer_config.json (deflated 76%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/scheduler.pt (deflated 56%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/optimizer.pt (deflated 17%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/trainer_state.json (deflated 64%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/special_tokens_map.json (deflated 85%)\n",
      "  adding: kaggle/working/results/checkpoint-1548/rng_state.pth (deflated 25%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/results.zip /kaggle/working/results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T08:00:30.033414Z",
     "iopub.status.busy": "2024-11-25T08:00:30.032492Z",
     "iopub.status.idle": "2024-11-25T08:00:51.090912Z",
     "shell.execute_reply": "2024-11-25T08:00:51.090028Z",
     "shell.execute_reply.started": "2024-11-25T08:00:30.033363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/fine_tuned_visobert/ (stored 0%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/sentencepiece.bpe.model (deflated 50%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/tokenizer.json (deflated 78%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/config.json (deflated 50%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/tokenizer_config.json (deflated 76%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/fine_tuned_visobert/special_tokens_map.json (deflated 85%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/fine_tuned_visobert.zip /kaggle/working/fine_tuned_visobert"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6156673,
     "sourceId": 10002107,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
